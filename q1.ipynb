{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSkLeJePnmLP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import math\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(42)"
      ],
      "metadata": {
        "id": "-vpD9geMoDbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s8N8js7oFkU",
        "outputId": "9ba395a9-b376-402d-d98a-c88901987213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"img_size\": 32,\n",
        "    \"patch_size\": 4,\n",
        "    \"in_chans\": 3,\n",
        "    \"num_classes\": 10,\n",
        "    \"embed_dim\": 192,\n",
        "    \"depth\": 8,\n",
        "    \"num_heads\": 8,\n",
        "    \"mlp_ratio\": 4.0,\n",
        "    \"dropout\": 0.1,\n",
        "    \"attn_dropout\": 0.1,\n",
        "    \"lr\": 3e-4,\n",
        "    \"weight_decay\": 0.05,\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 50,\n",
        "    \"grad_clip\": None,\n",
        "    \"warmup_steps\": 500,\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "OLEIUAYroKgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = (0.4914, 0.4822, 0.4465)\n",
        "std  = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])\n",
        "\n",
        "data_root = \"./data\"\n",
        "train_dataset = datasets.CIFAR10(root=data_root, train=True, download=True, transform=train_transform)\n",
        "test_dataset  = datasets.CIFAR10(root=data_root, train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=config[\"batch_size\"], shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}, Test size: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PcyGVtnoMSd",
        "outputId": "670a3456-5612-486f-9548-0a7717765f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 43.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 50000, Test size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: MixUp helpers\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "def mixup_data(x, y, alpha=0.8):\n",
        "    \"\"\"Returns mixed inputs, pairs of targets, and lambda\"\"\"\n",
        "    if alpha <= 0:\n",
        "        return x, y, 1.0, y, 1.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, lam, y_b\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n"
      ],
      "metadata": {
        "id": "L2lrfAlRH4wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=128):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0, \"img_size must be divisible by patch_size\"\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, H, W)\n",
        "        x = self.proj(x)\n",
        "        B, C, H, W = x.shape\n",
        "        x = x.flatten(2).transpose(1, 2)\n",
        "        return x"
      ],
      "metadata": {
        "id": "si81R0q3ojKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_pe = PatchEmbed(img_size=config[\"img_size\"], patch_size=config[\"patch_size\"], in_chans=config[\"in_chans\"], embed_dim=config[\"embed_dim\"])\n",
        "dummy = torch.randn(2, 3, 32, 32)\n",
        "out = _pe(dummy)\n",
        "print(\"PatchEmbed output shape:\", out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQBPTlQhokHD",
        "outputId": "4ea1a331-a932-4b58-e5f8-d8b82568389a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PatchEmbed output shape: torch.Size([2, 64, 192])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, dropout=0.0):\n",
        "        super().__init__()\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = nn.GELU()\n",
        "        self.fc2 = nn.Linear(hidden_features, in_features)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "zuv24bxRorMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, mlp_ratio=4.0, dropout=0.1, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=attn_dropout, batch_first=True)\n",
        "        self.drop1 = nn.Dropout(dropout)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.mlp = MLP(embed_dim, int(embed_dim * mlp_ratio), dropout)\n",
        "    def forward(self, x):\n",
        "        x_norm = self.norm1(x)\n",
        "        attn_out, _ = self.attn(x_norm, x_norm, x_norm, need_weights=False)\n",
        "        x = x + self.drop1(attn_out)\n",
        "        x_norm = self.norm2(x)\n",
        "        x = x + self.mlp(x_norm)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7U-RylqsosRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Module):\n",
        "    def __init__(self, img_size=32, patch_size=4, in_chans=3, num_classes=10,\n",
        "                 embed_dim=128, depth=6, num_heads=8, mlp_ratio=4.0, dropout=0.1, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
        "        num_patches = self.patch_embed.num_patches\n",
        "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
        "        self.pos_drop = nn.Dropout(p=dropout)\n",
        "        self.blocks = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, dropout=dropout, attn_dropout=attn_dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
        "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
        "            if m.bias is not None:\n",
        "                nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.LayerNorm):\n",
        "            nn.init.zeros_(m.bias)\n",
        "            nn.init.ones_(m.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B = x.shape[0]\n",
        "        x = self.patch_embed(x)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.pos_drop(x)\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        x = self.norm(x)\n",
        "        cls_out = x[:, 0]\n",
        "        logits = self.head(cls_out)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "RqyGG2fho1lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BatchWarmupCosineScheduler:\n",
        "    def __init__(self, optimizer, base_lr, total_steps, warmup_steps=0, min_lr=0.0):\n",
        "        self.optimizer = optimizer\n",
        "        self.base_lr = base_lr\n",
        "        self.total_steps = max(1, total_steps)\n",
        "        self.warmup_steps = max(0, warmup_steps)\n",
        "        self.min_lr = min_lr\n",
        "        self.step_num = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.step_num += 1\n",
        "        if self.step_num <= self.warmup_steps and self.warmup_steps > 0:\n",
        "            lr = self.base_lr * float(self.step_num) / float(max(1, self.warmup_steps))\n",
        "        else:\n",
        "            progress = float(self.step_num - self.warmup_steps) / float(max(1, self.total_steps - self.warmup_steps))\n",
        "            progress = min(max(progress, 0.0), 1.0)\n",
        "            lr = self.min_lr + 0.5 * (self.base_lr - self.min_lr) * (1.0 + math.cos(math.pi * progress))\n",
        "\n",
        "        for pg in self.optimizer.param_groups:\n",
        "            pg['lr'] = lr\n",
        "\n",
        "    def get_lr(self):\n",
        "        return self.optimizer.param_groups[0]['lr']\n"
      ],
      "metadata": {
        "id": "MmlkxS-QpnbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT(img_size=config[\"img_size\"], patch_size=config[\"patch_size\"], in_chans=config[\"in_chans\"],\n",
        "            num_classes=config[\"num_classes\"], embed_dim=config[\"embed_dim\"], depth=config[\"depth\"],\n",
        "            num_heads=config[\"num_heads\"], mlp_ratio=config[\"mlp_ratio\"], dropout=config[\"dropout\"], attn_dropout=config[\"attn_dropout\"])\n",
        "print(\"Model params (M):\", sum(p.numel() for p in model.parameters())/1e6)\n",
        "dummy = torch.randn(4, 3, 32, 32)\n",
        "print(\"Forward pass shape:\", model(dummy).shape)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w53DHsBCo2MF",
        "outputId": "8388e382-48a3-4eb1-a510-a6724bf3bd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model params (M): 3.583306\n",
            "Forward pass shape: torch.Size([4, 10])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViT(\n",
              "  (patch_embed): PatchEmbed(\n",
              "    (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
              "  )\n",
              "  (pos_drop): Dropout(p=0.1, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TransformerEncoderBlock(\n",
              "      (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "      )\n",
              "      (drop1): Dropout(p=0.1, inplace=False)\n",
              "      (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "      (mlp): MLP(\n",
              "        (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
              "        (act): GELU(approximate='none')\n",
              "        (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
              "        (drop): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "  (head): Linear(in_features=192, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append((correct_k.mul_(100.0 / batch_size)).item())\n",
        "        return res\n",
        "\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "scaler = GradScaler()\n",
        "\n",
        "def train_one_epoch_mixup(model, dataloader, criterion, optimizer, device, epoch, scheduler=None, grad_clip=None, mixup_alpha=0.8, use_amp=True):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Train Epoch {epoch}\")\n",
        "    for i, (images, targets) in pbar:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "\n",
        "        if mixup_alpha > 0:\n",
        "            images, targets_a, lam, targets_b = mixup_data(images, targets, mixup_alpha)\n",
        "        else:\n",
        "            targets_a, targets_b, lam = targets, targets, 1.0\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if use_amp:\n",
        "            with autocast():\n",
        "                outputs = model(images)\n",
        "                loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "            scaler.scale(loss).backward()\n",
        "            if grad_clip:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            outputs = model(images)\n",
        "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "            loss.backward()\n",
        "            if grad_clip:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "\n",
        "        if scheduler is not None:\n",
        "            if hasattr(scheduler, \"step\"):\n",
        "                scheduler.step()\n",
        "            elif callable(scheduler):\n",
        "                scheduler()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            _, preds = outputs.topk(1, dim=1)\n",
        "            preds = preds.squeeze(1)\n",
        "            correct = (preds == targets_a).float() * lam + (preds == targets_b).float() * (1 - lam)\n",
        "            acc1 = correct.mean().item() * 100.0\n",
        "\n",
        "        running_loss = (running_loss * i + loss.item()) / (i + 1)\n",
        "        running_acc = (running_acc * i + acc1) / (i + 1)\n",
        "        pbar.set_postfix(loss=running_loss, acc=running_acc)\n",
        "    return running_loss, running_acc\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc=\"Eval\")\n",
        "        for i, (images, targets) in pbar:\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            targets = targets.to(device, non_blocking=True)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, targets)\n",
        "            acc1 = accuracy(outputs, targets, topk=(1,))[0]\n",
        "            total_loss = (total_loss * i + loss.item()) / (i + 1)\n",
        "            total_acc = (total_acc * i + acc1) / (i + 1)\n",
        "            pbar.set_postfix(loss=total_loss, acc=total_acc)\n",
        "    return total_loss, total_acc\n"
      ],
      "metadata": {
        "id": "jYbZfw1so3rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26df0b06-188c-4d70-a6fc-ce5232094af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1705434590.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.smoothing = smoothing\n",
        "    def forward(self, x, target):\n",
        "        log_probs = F.log_softmax(x, dim=-1)\n",
        "        nll = -log_probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)\n",
        "        smooth_loss = -log_probs.mean(dim=-1)\n",
        "        loss = (1.0 - self.smoothing) * nll + self.smoothing * smooth_loss\n",
        "        return loss.mean()"
      ],
      "metadata": {
        "id": "PVtcHDA-IHZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
        "optimizer = AdamW(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "total_steps = len(train_loader) * config[\"epochs\"]\n",
        "warmup_steps = config.get(\"warmup_steps\", 500)\n",
        "\n",
        "scheduler = BatchWarmupCosineScheduler(optimizer, base_lr=config[\"lr\"], total_steps=total_steps, warmup_steps=warmup_steps, min_lr=1e-6)\n",
        "\n",
        "best_acc = 0.0\n",
        "history = {\"train_loss\": [], \"train_acc\": [], \"test_loss\": [], \"test_acc\": []}\n",
        "\n",
        "for epoch in range(1, config[\"epochs\"] + 1):\n",
        "    train_loss, train_acc = train_one_epoch_mixup(model, train_loader, criterion, optimizer, device, epoch, scheduler=scheduler, grad_clip=config.get(\"grad_clip\"))\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "    history[\"train_loss\"].append(train_loss); history[\"train_acc\"].append(train_acc)\n",
        "    history[\"test_loss\"].append(test_loss); history[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    if test_acc > best_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), \"best_vit_cifar10.pth\")\n",
        "        print(f\" => Saved best model with acc: {best_acc:.2f}%\")\n",
        "    print(f\"Epoch {epoch} summary -> train_acc: {train_acc:.2f}%, test_acc: {test_acc:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Css2h2vVo86w",
        "outputId": "e8d82d9a-1421-4b93-b10e-7b38874ac156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain Epoch 1:   0%|          | 0/391 [00:00<?, ?it/s]/tmp/ipython-input-1705434590.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "Train Epoch 1: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s, acc=20.2, loss=2.18]\n",
            "Eval: 100%|██████████| 79/79 [00:04<00:00, 18.21it/s, acc=35.7, loss=1.91]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 35.71%\n",
            "Epoch 1 summary -> train_acc: 20.21%, test_acc: 35.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 2: 100%|██████████| 391/391 [00:46<00:00,  8.37it/s, acc=27.5, loss=2.06]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 21.54it/s, acc=41.1, loss=1.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 41.14%\n",
            "Epoch 2 summary -> train_acc: 27.54%, test_acc: 41.14%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 3: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s, acc=32.5, loss=1.98]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.63it/s, acc=47.1, loss=1.64]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 47.13%\n",
            "Epoch 3 summary -> train_acc: 32.53%, test_acc: 47.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 4: 100%|██████████| 391/391 [00:44<00:00,  8.86it/s, acc=36, loss=1.92]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.85it/s, acc=50.8, loss=1.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 50.84%\n",
            "Epoch 4 summary -> train_acc: 35.99%, test_acc: 50.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 5: 100%|██████████| 391/391 [00:43<00:00,  9.02it/s, acc=37.4, loss=1.89]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 22.07it/s, acc=53.6, loss=1.52]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 53.62%\n",
            "Epoch 5 summary -> train_acc: 37.43%, test_acc: 53.62%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 6: 100%|██████████| 391/391 [00:42<00:00,  9.12it/s, acc=38.9, loss=1.87]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.98it/s, acc=57.3, loss=1.44]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 57.33%\n",
            "Epoch 6 summary -> train_acc: 38.90%, test_acc: 57.33%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 7: 100%|██████████| 391/391 [00:44<00:00,  8.85it/s, acc=39.4, loss=1.86]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 20.57it/s, acc=56.9, loss=1.47]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 summary -> train_acc: 39.41%, test_acc: 56.91%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 8: 100%|██████████| 391/391 [00:51<00:00,  7.64it/s, acc=40.9, loss=1.83]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.41it/s, acc=58.1, loss=1.43]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 58.11%\n",
            "Epoch 8 summary -> train_acc: 40.89%, test_acc: 58.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 9: 100%|██████████| 391/391 [00:45<00:00,  8.67it/s, acc=41.3, loss=1.83]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.40it/s, acc=60.7, loss=1.38]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 60.74%\n",
            "Epoch 9 summary -> train_acc: 41.34%, test_acc: 60.74%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 10: 100%|██████████| 391/391 [00:43<00:00,  8.89it/s, acc=42.4, loss=1.8]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 23.57it/s, acc=60.8, loss=1.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 60.76%\n",
            "Epoch 10 summary -> train_acc: 42.42%, test_acc: 60.76%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 11: 100%|██████████| 391/391 [00:43<00:00,  8.89it/s, acc=42.8, loss=1.8]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.14it/s, acc=62.5, loss=1.33]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 62.45%\n",
            "Epoch 11 summary -> train_acc: 42.83%, test_acc: 62.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 12: 100%|██████████| 391/391 [00:44<00:00,  8.74it/s, acc=43.1, loss=1.79]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.55it/s, acc=63, loss=1.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 63.04%\n",
            "Epoch 12 summary -> train_acc: 43.12%, test_acc: 63.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 13: 100%|██████████| 391/391 [00:44<00:00,  8.70it/s, acc=43.9, loss=1.78]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.96it/s, acc=63.6, loss=1.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 63.59%\n",
            "Epoch 13 summary -> train_acc: 43.94%, test_acc: 63.59%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 14: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s, acc=45, loss=1.76]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 24.02it/s, acc=65.3, loss=1.27]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 65.35%\n",
            "Epoch 14 summary -> train_acc: 45.00%, test_acc: 65.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 15: 100%|██████████| 391/391 [00:43<00:00,  8.94it/s, acc=45.2, loss=1.76]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.67it/s, acc=65, loss=1.27]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 summary -> train_acc: 45.18%, test_acc: 64.99%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 16: 100%|██████████| 391/391 [00:44<00:00,  8.75it/s, acc=46.1, loss=1.74]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.84it/s, acc=66.5, loss=1.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 66.51%\n",
            "Epoch 16 summary -> train_acc: 46.07%, test_acc: 66.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 17: 100%|██████████| 391/391 [00:45<00:00,  8.58it/s, acc=46.7, loss=1.73]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 22.46it/s, acc=67.4, loss=1.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 67.41%\n",
            "Epoch 17 summary -> train_acc: 46.73%, test_acc: 67.41%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 18: 100%|██████████| 391/391 [00:48<00:00,  8.11it/s, acc=48.4, loss=1.7]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 23.51it/s, acc=68.2, loss=1.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 68.19%\n",
            "Epoch 18 summary -> train_acc: 48.45%, test_acc: 68.19%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 19: 100%|██████████| 391/391 [00:43<00:00,  8.91it/s, acc=47.7, loss=1.71]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.75it/s, acc=69.9, loss=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 69.87%\n",
            "Epoch 19 summary -> train_acc: 47.74%, test_acc: 69.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 20: 100%|██████████| 391/391 [00:44<00:00,  8.82it/s, acc=48.6, loss=1.69]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.59it/s, acc=68.9, loss=1.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 summary -> train_acc: 48.63%, test_acc: 68.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 21: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s, acc=48.8, loss=1.7]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 23.78it/s, acc=70.2, loss=1.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 70.23%\n",
            "Epoch 21 summary -> train_acc: 48.80%, test_acc: 70.23%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 22: 100%|██████████| 391/391 [00:43<00:00,  8.89it/s, acc=49.9, loss=1.67]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 24.97it/s, acc=68.3, loss=1.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 summary -> train_acc: 49.89%, test_acc: 68.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 23: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s, acc=50.3, loss=1.66]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.68it/s, acc=72.2, loss=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 72.24%\n",
            "Epoch 23 summary -> train_acc: 50.32%, test_acc: 72.24%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 24: 100%|██████████| 391/391 [00:44<00:00,  8.79it/s, acc=50, loss=1.67]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.20it/s, acc=72.8, loss=1.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 72.77%\n",
            "Epoch 24 summary -> train_acc: 50.00%, test_acc: 72.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 25: 100%|██████████| 391/391 [00:43<00:00,  8.95it/s, acc=49.8, loss=1.67]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 21.14it/s, acc=72.4, loss=1.12]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 summary -> train_acc: 49.80%, test_acc: 72.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 26: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s, acc=50.9, loss=1.66]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.81it/s, acc=72.8, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 72.77%\n",
            "Epoch 26 summary -> train_acc: 50.86%, test_acc: 72.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 27: 100%|██████████| 391/391 [00:44<00:00,  8.84it/s, acc=51.1, loss=1.65]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.56it/s, acc=73.6, loss=1.1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 73.65%\n",
            "Epoch 27 summary -> train_acc: 51.12%, test_acc: 73.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 28: 100%|██████████| 391/391 [00:44<00:00,  8.86it/s, acc=50.9, loss=1.66]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.14it/s, acc=74.8, loss=1.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 74.78%\n",
            "Epoch 28 summary -> train_acc: 50.86%, test_acc: 74.78%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 29: 100%|██████████| 391/391 [00:43<00:00,  8.98it/s, acc=52.9, loss=1.62]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 21.95it/s, acc=74.3, loss=1.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 summary -> train_acc: 52.90%, test_acc: 74.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 30: 100%|██████████| 391/391 [00:43<00:00,  8.99it/s, acc=51.4, loss=1.64]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.72it/s, acc=74.5, loss=1.08]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 summary -> train_acc: 51.42%, test_acc: 74.53%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 31: 100%|██████████| 391/391 [00:44<00:00,  8.85it/s, acc=52.3, loss=1.63]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.41it/s, acc=76.1, loss=1.05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 76.10%\n",
            "Epoch 31 summary -> train_acc: 52.29%, test_acc: 76.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 32: 100%|██████████| 391/391 [00:44<00:00,  8.87it/s, acc=54.7, loss=1.58]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.15it/s, acc=76.4, loss=1.04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 76.40%\n",
            "Epoch 32 summary -> train_acc: 54.66%, test_acc: 76.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 33: 100%|██████████| 391/391 [00:43<00:00,  9.07it/s, acc=53.6, loss=1.6]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 21.77it/s, acc=76.2, loss=1.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 summary -> train_acc: 53.62%, test_acc: 76.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 34: 100%|██████████| 391/391 [00:43<00:00,  9.02it/s, acc=53.2, loss=1.6]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.04it/s, acc=76.1, loss=1.05]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 summary -> train_acc: 53.20%, test_acc: 76.08%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 35: 100%|██████████| 391/391 [00:45<00:00,  8.69it/s, acc=53.7, loss=1.6]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.13it/s, acc=77.4, loss=1.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 77.38%\n",
            "Epoch 35 summary -> train_acc: 53.69%, test_acc: 77.38%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 36: 100%|██████████| 391/391 [00:45<00:00,  8.67it/s, acc=54.4, loss=1.58]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 25.97it/s, acc=77.7, loss=1.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 77.65%\n",
            "Epoch 36 summary -> train_acc: 54.44%, test_acc: 77.65%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 37: 100%|██████████| 391/391 [00:45<00:00,  8.60it/s, acc=54.7, loss=1.58]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.52it/s, acc=77.1, loss=1.02]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 summary -> train_acc: 54.72%, test_acc: 77.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 38: 100%|██████████| 391/391 [00:44<00:00,  8.86it/s, acc=55, loss=1.57]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 22.01it/s, acc=77.3, loss=1.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 summary -> train_acc: 55.04%, test_acc: 77.28%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 39: 100%|██████████| 391/391 [00:43<00:00,  9.02it/s, acc=54.9, loss=1.57]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.15it/s, acc=77.6, loss=1.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 summary -> train_acc: 54.93%, test_acc: 77.63%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 40: 100%|██████████| 391/391 [00:44<00:00,  8.73it/s, acc=55.5, loss=1.56]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 25.95it/s, acc=78.1, loss=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 78.11%\n",
            "Epoch 40 summary -> train_acc: 55.46%, test_acc: 78.11%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 41: 100%|██████████| 391/391 [00:44<00:00,  8.71it/s, acc=55.6, loss=1.56]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.78it/s, acc=78.2, loss=1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 78.15%\n",
            "Epoch 41 summary -> train_acc: 55.65%, test_acc: 78.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 42: 100%|██████████| 391/391 [00:44<00:00,  8.70it/s, acc=55.6, loss=1.56]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 26.10it/s, acc=78.3, loss=0.998]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 78.34%\n",
            "Epoch 42 summary -> train_acc: 55.61%, test_acc: 78.34%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 43: 100%|██████████| 391/391 [00:43<00:00,  8.97it/s, acc=55.7, loss=1.56]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 21.13it/s, acc=77.7, loss=1.01]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43 summary -> train_acc: 55.72%, test_acc: 77.75%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 44: 100%|██████████| 391/391 [00:43<00:00,  8.96it/s, acc=56.5, loss=1.54]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.74it/s, acc=78.2, loss=0.997]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44 summary -> train_acc: 56.52%, test_acc: 78.18%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 45: 100%|██████████| 391/391 [00:44<00:00,  8.84it/s, acc=56.5, loss=1.54]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.28it/s, acc=78.3, loss=0.995]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45 summary -> train_acc: 56.50%, test_acc: 78.31%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 46: 100%|██████████| 391/391 [00:44<00:00,  8.85it/s, acc=55.6, loss=1.55]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.75it/s, acc=78.5, loss=0.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " => Saved best model with acc: 78.54%\n",
            "Epoch 46 summary -> train_acc: 55.62%, test_acc: 78.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 47: 100%|██████████| 391/391 [00:43<00:00,  9.00it/s, acc=55.4, loss=1.57]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 22.98it/s, acc=78.5, loss=0.99]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47 summary -> train_acc: 55.36%, test_acc: 78.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 48: 100%|██████████| 391/391 [00:43<00:00,  8.98it/s, acc=56.8, loss=1.54]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 26.62it/s, acc=78.5, loss=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48 summary -> train_acc: 56.76%, test_acc: 78.51%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 49: 100%|██████████| 391/391 [00:44<00:00,  8.82it/s, acc=55.8, loss=1.56]\n",
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.15it/s, acc=78.5, loss=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49 summary -> train_acc: 55.82%, test_acc: 78.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train Epoch 50: 100%|██████████| 391/391 [00:44<00:00,  8.77it/s, acc=56.6, loss=1.54]\n",
            "Eval: 100%|██████████| 79/79 [00:03<00:00, 25.94it/s, acc=78.5, loss=0.988]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 summary -> train_acc: 56.59%, test_acc: 78.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_path = \"best_vit_cifar10.pth\"\n",
        "if os.path.exists(best_path):\n",
        "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Best model test accuracy: {test_acc:.2f}%\")\n",
        "else:\n",
        "    print(\"No saved model found, evaluate current model instead.\")\n",
        "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Current model test accuracy: {test_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2cQS_5Lo-Rk",
        "outputId": "4298c1aa-a2e8-43b3-b6ff-4f76e8e266dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Eval: 100%|██████████| 79/79 [00:02<00:00, 27.38it/s, acc=78.5, loss=0.99]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model test accuracy: 78.54%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}